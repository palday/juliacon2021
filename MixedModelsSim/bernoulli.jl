### A Pluto.jl notebook ###
# v0.14.5

using Markdown
using InteractiveUtils

# ╔═╡ d951e119-09f7-4b4e-a155-7e1ce0459317
begin
	using CairoMakie # for graphics
	using DataFrames
	using Distributions
	using MixedModels, MixedModelsSim
	using Random
end

# ╔═╡ 288bb980-b105-11eb-1687-73eaf51c6e80
md"""
# Simulating an Unbalanced Bernoulli Experiment from Scratch using `MixedModels.jl` and `MixedModelsSim.jl`

*Phillip M. Alday, 2021-05-11*

Today, we're using Pluto notebooks. If you used Jupyter/iPython notebooks, this will seem similar. Pluto has two really cool advantages over those:
1. Pluto is *reactive*: if I change a variable up at the top of the notebook, the changes propogate throughout the notebook. So there's no mixed up state from doing things out of order.
2. Pluto files are stored as plain-text Julia-language files, so you can read and run their source code like any other source code file.

If you haven't already done so, you should checkout `power.jl` for a more general introduction.

First, some setup
"""

# ╔═╡ 89b539d4-f564-4648-bf2b-7ee9c92687c8
md"""
## Assemble the Design

We're going to do a simple, within-subjects oddball design with two conditions:

1. **standard**
2. **deviant** 


For details on more complicated designs, checkout `power.jl`.  Here, we just want to focus on the GLMM aspects. 

This also has the side benefit of showing how you can still use `MixedModelsSim` even when you don't have items, even though the interface assumes two grouping variables.
Likewise, you can construct imbalanced designs, even thought interface currently assumes balance. 

We're working on improving the interface and making all of these things even easier.

For now, let's create imbalance by just repeating the `standard` condition a few 
times. We'll use 80% standards and 20% deviants.
"""

# ╔═╡ 47f0e82d-abec-421a-a0a0-03d791dddf70
conditions = Dict(:condition => [ repeat(["standard"], 4); "deviant" ] )

# ╔═╡ 0ea1d41b-d225-4082-aa6b-5bc80beda96b
n_subj = 20

# ╔═╡ f21054f3-77d7-42db-be8e-a136be631aba
md"""Even though we don't have items per se, we still want each subject to see each condition more than once, we specify the number of items as the number of trials each subject will see.
To get the right number of trials, we specify our `conditions` as a between item vector. 
Note that this will give an error if the length of the condition vector doesn't divide the number of trials.
In other words, you'll get an error if the number of trials could not allow for the (im)balance of your condition vector to be preserved:
"""

# ╔═╡ 1be3f073-9cc4-4184-9ac4-5138ee394b19
simdat_crossed(MersenneTwister(42), n_subj, 33;
                            item_btwn = conditions)

# ╔═╡ 66ddef94-809c-4117-9ffa-a87790a3bc35
n_trials = 100

# ╔═╡ 823f06a3-1ba6-4c5f-b842-d2dee7bc8d3e
begin
	design = simdat_crossed(MersenneTwister(42), n_subj, n_trials;
                            item_btwn = conditions)
	design = pooled!(DataFrame(design))
end

# ╔═╡ 04e3ba6d-83d1-4d9b-93b8-b72ed738972d
md"""
There are a few things to note here: 

- an `item` column was generated, but we don't actually care about it. So we can ignore it! (If you didn't specify any between-item conditions and left out the number of items, then the number of items would default to 1 and you would get an item column with a single unique identifier.)
- the autogenerated column `dv` for our dependent variable that has been pre-populated with noise from a standard normal distribution ($N(0,1)$). For a Bernoulli model, that's not what we want. 

Let's clean this up a bit before continuing on. We'll get rid of the extra item column and replace `dv` with a Bernoulli random variable.
"""

# ╔═╡ 43215132-34fe-4fbb-8ca1-8ea9eb433402
begin
	design_bernoulli = select(design, Not(:item))
	# note that in a Bernoulli model, there is no residual variability 
 	# more technically: there is no dispersion parameter to estimate
	# so we can use whatever probability to populate the dv here
	# because it won't play a role in the simulation
	# we just need something that won't lead to total separation (i.e. no 0 nor 1)
	design_bernoulli[!, :dv] = rand(Bernoulli(0.5), nrow(design_bernoulli))
	design_bernoulli
end

# ╔═╡ d9f9f5cc-04af-4b50-b725-72160422c45a
md"""
But before we get to simulating, let's fit the model to the noise, just to see how things look. We're going to use effects coding for our contrasts.
"""

# ╔═╡ 95c03f4a-6e86-4fab-b706-039834b06c4d
contrasts = Dict(:condition => EffectsCoding(base="standard"))

# ╔═╡ d9209d7f-8206-497f-a5dc-68c4cda53ec3
form = @formula(dv ~ 1 + condition + (1 + condition | subj))

# ╔═╡ f4baf339-74f9-4211-b56d-83fe481977bb
m0 = fit(MixedModel, form, design_bernoulli, Bernoulli(); contrasts=contrasts, fast=true)

# ╔═╡ 51db88e8-0658-4d5f-b299-ea1b9f1939f8
md"""
## Assemble the Random Effects

The hard part in simulating right now is specifying the random effects.
We're working on making this bit easier, but you need to specify the variance-covariance matrix of the random effects. You can see what this
looks like:
"""

# ╔═╡ 69a18181-f46e-4c9e-a79f-80db0d9fc902
VarCorr(m0)

# ╔═╡ 3e3dc064-5854-4ec5-b710-a4cca1c17060
md"""
For each grouping variable (subjects and items), there are two major components: the standard deviations ahd the correlations.

For this example, we'll just assume all the correlations and thus the covariances are 0 in order to make things simple.
Then we only have to worry about the standard deviations.

Let's assume that the standard deviation between subjects

- in the intercept is 1.5 
- in condition is 1.2
- the correlation between these two is -0.2

Note these are always specified relative to the residual standard deviation.
In other words, we think about how big the between-subject differences are relative to the between-observation differences. In a Bernoulli model, the residual standard deviation (or more precisely, the *dispersion*) is taken to be 1 by definition and convention. That said, the random effects are on the scale of the linear predictor, i.e. on the logit scale and not the probability scale.

We can now create the associated covariance matrices.[^cholesky]

[^cholesky]: Technically, we're creating the lower Cholesky factor of these matrices, which is a bit like the matrix square root. In other words, we're creating the matrix form of standard deviations instead of the matrix form of the variances.]
"""

# ╔═╡ 90dd7f51-822d-4ebb-906c-afd9649f3e83
corr_subj = [+1.0 -0.2 
			 -0.2 +1.0]

# ╔═╡ b370aa4e-1341-45c5-9ab8-e4f29ef28e98
re_subj = create_re(1.5, 1.2; corrmat=corr_subj)

# ╔═╡ 0414d540-7f4c-4231-8e01-3c097d13b538
md"""
We can check that we got these right by installing these parameter values into the model.
Note that we have to specify them in the same order as in the output from `VarCorr`.
"""

# ╔═╡ 4496e1bc-f4d7-41ac-bd36-8a75c4725fdf
begin
	# we make a copy to avoid changing the results above with reactivity
	m1 = deepcopy(m0)
	# CairoMakie also has a function update!, so we have to be specific
	m1 = MixedModelsSim.update!(m1, re_subj)
	VarCorr(m1)
end

# ╔═╡ 631ab549-c771-4974-a3d0-2c6a26e90f73
md"""
Looks good. The values don't exactly match the values in our parameter vector because the
residual standard deviation isn't exactly 1.0.

For the actual simulation, we'll need the compact form of these covariance matrices that MixedModels.jl stores uses internally.
This compact form is the parameter vector θ and we can get it back out of the model where we just installed it:
"""

# ╔═╡ f0fefbcb-51b8-458e-9fe0-96c1820e0b56
θ = m1.θ

# ╔═╡ 733ea084-7bf0-4658-9b37-dd9a749dee53
md"""
## Assemble the Fixed Effects

The last two components we need are the residual variance and the effect sizes for the fixed effects.
"""

# ╔═╡ bc087a8a-a183-4b17-a566-4561eac5d668
# average about 75% accuracy acros conditions, lose about 10% accuracy on deviant condition
β = [1.0, -0.48] 

# ╔═╡ 25762800-7fea-4f2c-b6c2-978d85db45bd
md"""
The entries in the β correspond to the coefficients in the model given by
"""

# ╔═╡ 16ecfacb-f118-4358-b9b1-385f39bbc293
coefnames(m1)

# ╔═╡ 1e0c3594-dec8-4bc6-8801-70382f3df7a5
md"""
## Simulate a Single Dataset

Now we're ready to actually simulate our data. 
Let's start small and simulate a single dataset and see if we're able to recover our parameter values.
"""

# ╔═╡ aa4ddaa2-f9b3-40b1-8f41-3d7478476948
begin
	# making a deepcopy here so that our previews above aren't impacted
	m_test = simulate!(MersenneTwister(42), deepcopy(m0); β=β, θ=θ)
	refit!(m_test)
end

# ╔═╡ fa18b2f3-ef07-4920-8684-8b963714545c
VarCorr(m_test)

# ╔═╡ 8af80b54-eff9-4a72-a269-811f7940f057
abs.(coef(m_test) - β) .< stderror(m_test)

# ╔═╡ 5f58663b-ca74-405d-b6e7-eb1a4cf856ba
md"""
## Simulate a Lot of Datasets

We can use `parametricbootstrap` to do this: the parametric bootstrap actually works by simulating new data from an existing model and then looking at how the estimates fit to that new data look.
In MixedModels.jl, you can specify different parameter values, such as the ones
 we made up for our fake data.
"""

# ╔═╡ a2e16602-7d63-4fce-aed0-55a40febd3e7
n_sim = 100

# ╔═╡ ea3448a9-cb0c-4a8e-8ee0-ccf883f27511
sim = parametricbootstrap(MersenneTwister(12321), n_sim, m0; β=β, θ=θ)

# ╔═╡ b87b7850-8660-4730-a557-2e64d73d36d0
DataFrame(shortestcovint(sim))

# ╔═╡ c4fadf55-c23d-435b-b6b5-40a7301674a6
md"""
## See your power and profit!

Finally, we can turn this into a power table:
"""

# ╔═╡ 6cfe68cd-7183-4aa6-8011-ef5dd06ff0f7
DataFrame(power_table(sim))

# ╔═╡ 272fa69b-470a-4ee5-9be2-7e39955c7d45
md"""
We should also checkout how many fits were singular. 
Singular fits are a sign that we actually don't have enough power to reliably distinguish the participant/item variation from the residual variation.
If we're not doing a study on individual differences, that's probably okay, but it also suggests we could simplify our model design and make our lives easier.
"""

# ╔═╡ d74266d1-48c6-4ba8-9b0b-c99b94822d02
count(issingular(sim))

# ╔═╡ 969260cd-708f-4520-8d55-5b3c298df615
md"""
## What's better: more subjects or more trials?

It depends -- on all the parameters we set up above: the fixed and random effects, and where applicable, the dispersion paramater.


But assuming, we're going with all the parameters we chose above, we can simulate a few different numbers of subjects and a few different number of trials and see what has the most impact.
"""

# ╔═╡ 515ce8d4-6bdc-447c-91b2-69dcf3c0226e
begin
	
ptab = DataFrame()
dist = Bernoulli(0.5)
rng = MersenneTwister(6500)	
n_iter = 100
	
for ns in 20:5:50, nt in 100:100:1000
	d = DataFrame(simdat_crossed(MersenneTwister(42), ns, nt; item_btwn = conditions))
	select!(d, Not(:item))
	d[!, :dv] = rand(dist, nrow(d))
	this_mod = GeneralizedLinearMixedModel(form, d, Bernoulli(); contrasts=contrasts)
	this_sim = parametricbootstrap(rng, n_iter, this_mod; β=β, θ=θ, use_threads=true)
		
	p = DataFrame(power_table(this_sim))
	p[!, :n_subj] .= float(ns)
	p[!, :n_item] .= float(nt)
	append!(ptab, p)
end
	
ptab
end

# ╔═╡ 6d452430-cff9-4cf6-bb4a-cf01106ca72e
begin
	f = Figure(resolution = (800, 600); title = "Power by Number of Subjects and Number of Trials")
	
	ncoef = 2
	axs = sizehint!(Axis[], ncoef)
	cmap = Any[missing]
	
	for (ii, gdf) in enumerate(groupby(ptab, :coefname))
		df = unstack(select(gdf, [:power, :n_subj, :n_item]), :n_item, :n_subj, :power)

		ax = Axis(f[1, ii]; title = only(unique(gdf.coefname)))
		push!(axs, ax)
		ax.xlabel = "n Subjects"
		ax.ylabel = "n Trials"
		xs = parse.(Float64, names(df)[2:end])
		ys = df[:, 1]
		zs = Matrix(disallowmissing!(df[:, 2:end]))'
		co = contourf!(xs, ys, zs, levels = 0.0:0.05:1.05)	
		cmap[1] = co
	end
	
	linkaxes!(axs...)
	cbar = Colorbar(f[1, ncoef+1], only(cmap); label = "Estimated Power", width=20)
	f
end

# ╔═╡ Cell order:
# ╟─288bb980-b105-11eb-1687-73eaf51c6e80
# ╠═d951e119-09f7-4b4e-a155-7e1ce0459317
# ╟─89b539d4-f564-4648-bf2b-7ee9c92687c8
# ╠═47f0e82d-abec-421a-a0a0-03d791dddf70
# ╠═0ea1d41b-d225-4082-aa6b-5bc80beda96b
# ╟─f21054f3-77d7-42db-be8e-a136be631aba
# ╠═1be3f073-9cc4-4184-9ac4-5138ee394b19
# ╠═66ddef94-809c-4117-9ffa-a87790a3bc35
# ╠═823f06a3-1ba6-4c5f-b842-d2dee7bc8d3e
# ╟─04e3ba6d-83d1-4d9b-93b8-b72ed738972d
# ╠═43215132-34fe-4fbb-8ca1-8ea9eb433402
# ╟─d9f9f5cc-04af-4b50-b725-72160422c45a
# ╠═95c03f4a-6e86-4fab-b706-039834b06c4d
# ╠═d9209d7f-8206-497f-a5dc-68c4cda53ec3
# ╠═f4baf339-74f9-4211-b56d-83fe481977bb
# ╟─51db88e8-0658-4d5f-b299-ea1b9f1939f8
# ╠═69a18181-f46e-4c9e-a79f-80db0d9fc902
# ╟─3e3dc064-5854-4ec5-b710-a4cca1c17060
# ╠═90dd7f51-822d-4ebb-906c-afd9649f3e83
# ╠═b370aa4e-1341-45c5-9ab8-e4f29ef28e98
# ╟─0414d540-7f4c-4231-8e01-3c097d13b538
# ╠═4496e1bc-f4d7-41ac-bd36-8a75c4725fdf
# ╟─631ab549-c771-4974-a3d0-2c6a26e90f73
# ╠═f0fefbcb-51b8-458e-9fe0-96c1820e0b56
# ╟─733ea084-7bf0-4658-9b37-dd9a749dee53
# ╠═bc087a8a-a183-4b17-a566-4561eac5d668
# ╟─25762800-7fea-4f2c-b6c2-978d85db45bd
# ╠═16ecfacb-f118-4358-b9b1-385f39bbc293
# ╟─1e0c3594-dec8-4bc6-8801-70382f3df7a5
# ╠═aa4ddaa2-f9b3-40b1-8f41-3d7478476948
# ╠═fa18b2f3-ef07-4920-8684-8b963714545c
# ╠═8af80b54-eff9-4a72-a269-811f7940f057
# ╟─5f58663b-ca74-405d-b6e7-eb1a4cf856ba
# ╠═a2e16602-7d63-4fce-aed0-55a40febd3e7
# ╠═ea3448a9-cb0c-4a8e-8ee0-ccf883f27511
# ╠═b87b7850-8660-4730-a557-2e64d73d36d0
# ╟─c4fadf55-c23d-435b-b6b5-40a7301674a6
# ╠═6cfe68cd-7183-4aa6-8011-ef5dd06ff0f7
# ╟─272fa69b-470a-4ee5-9be2-7e39955c7d45
# ╠═d74266d1-48c6-4ba8-9b0b-c99b94822d02
# ╟─969260cd-708f-4520-8d55-5b3c298df615
# ╠═515ce8d4-6bdc-447c-91b2-69dcf3c0226e
# ╠═6d452430-cff9-4cf6-bb4a-cf01106ca72e
